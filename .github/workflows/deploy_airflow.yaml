name: Deploy Databricks Infrastructure

on:
  push:
    branches:
      - main
  workflow_dispatch:  # manual trigger

jobs:
  terraform:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        env: [dev]

    env:
      ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: List terraform folder contents
        run: ls -la terraform/${{ matrix.env }}/databricks

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7

      - name: Terraform Init
        working-directory: terraform/${{ matrix.env }}/databricks
        run: terraform init

      - name: Terraform Plan
        working-directory: terraform/${{ matrix.env }}/databricks
        run: terraform plan \
          -var "azure_credentials=${{ secrets.AZURE_CREDENTIALS }}" \
          -var "acr_sp_username=${{ secrets.ACR_SP_USERNAME }}" \
          -var "acr_sp_password=${{ secrets.ACR_SP_PASSWORD }}" \
          -var-file=terraform.tfvars

      - name: Terraform Apply
        if: ${{ github.ref == format('refs/heads/{0}', matrix.env) }}
        working-directory: terraform/${{ matrix.env }}/databricks
        run: terraform apply -auto-approve \
          -var "azure_credentials=${{ secrets.AZURE_CREDENTIALS }}" \
          -var "acr_sp_username=${{ secrets.ACR_SP_USERNAME }}" \
          -var "acr_sp_password=${{ secrets.ACR_SP_PASSWORD }}" \
          -var-file=terraform.tfvars

      - name: Install Databricks CLI & jq
        run: |
          pip install databricks-cli
          sudo apt-get update && sudo apt-get install -y jq

      - name: Configure Databricks CLI
        run: |
          databricks configure --token <<EOF
          ${{ secrets.DATABRICKS_HOST }}
          ${{ secrets.DATABRICKS_TOKEN }}
          EOF

      - name: Create /Shared/project folder in Databricks Workspace
        run: databricks workspace mkdirs /Shared/project

      - name: Upload Notebooks to Workspace
        run: |
          echo "Uploading notebooks to /Shared/project..."
          for nb in notebooks/*; do
            base=$(basename "$nb")
            databricks workspace import --language PYTHON --format SOURCE --overwrite "$nb" "/Shared/project/$base"
          done

  terraform_destroy:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        env: [dev]

    env:
      ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7

      - name: Terraform Init
        working-directory: terraform/${{ matrix.env }}/databricks
        run: terraform init

      - name: Terraform Destroy
        working-directory: terraform/${{ matrix.env }}/databricks
        run: terraform destroy -auto-approve \
          -var "azure_credentials=${{ secrets.AZURE_CREDENTIALS }}" \
          -var "acr_sp_username=${{ secrets.ACR_SP_USERNAME }}" \
          -var "acr_sp_password=${{ secrets.ACR_SP_PASSWORD }}" \
          -var-file=terraform.tfvars
